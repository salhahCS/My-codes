{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNkmHKogjBoZPUsIxklNzWx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salhahCS/My-codes/blob/main/4DecYOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENz7y5QwcC6H",
        "outputId": "90590e4e-dae9-4060-faf5-fcdf1d02f55f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "first, i should Mount Google Drive\n",
        "Access dataset on drive\n",
        "dataste 3 groups: train (7 videos), validation (video 11,12 from training), teating (9 vidoes)\n",
        "i cleaned the dataset to contain only 2 classes: Non-Human Object and Moving In Opposite. rewrite again full guide.\n",
        "we detect the abnormality in pedstraint in HAJJ.\n",
        "the dataset originally splited into train and test, 9 videos for each group, i added validation to fune-tune my YOLO model.\n",
        "/content/drive/MyDrive/ProjectDataset\n",
        "/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset\n",
        "/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Testing\n",
        "/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training\n",
        "/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Validation\n"
      ],
      "metadata": {
        "id": "o6zAYO2rc-oK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas opencv-python-headless\n",
        "#Install Required Libraries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnCijckMeLGs",
        "outputId": "906ad38c-542a-499d-f269-f758cfd2c0e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert CSV Labels to YOLO Format\n",
        "\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def convert_to_yolo_format(video_file, csv_file, output_dir):\n",
        "    # Read the label CSV file\n",
        "    labels = pd.read_csv(csv_file)\n",
        "\n",
        "    # Open video file to extract frame size (width, height)\n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    ret, frame = cap.read()\n",
        "    height, width, _ = frame.shape  # Get frame size\n",
        "    cap.release()\n",
        "\n",
        "    # Process each frame in the label file\n",
        "    for _, row in labels.iterrows():\n",
        "        # Extract the frame number and corresponding bounding box coordinates\n",
        "        frame_number = row['Frame_No']\n",
        "        x_center = (row['X'] + row['Width'] / 2) / width\n",
        "        y_center = (row['Y'] + row['Height'] / 2) / height\n",
        "        w = row['Width'] / width\n",
        "        h = row['Height'] / height\n",
        "\n",
        "        # Map the class to its respective ID (0 for 'Moving Non-Human Object', 1 for 'Moving In Opposite')\n",
        "        if row['Classes'] == 'Moving Non-Human Object':\n",
        "            class_id = 0\n",
        "        elif row['Classes'] == 'Moving In Opposite':\n",
        "            class_id = 1\n",
        "        else:\n",
        "            continue  # Skip other classes\n",
        "\n",
        "        # Define the YOLO annotation file name (same as frame number)\n",
        "        yolo_annotation_path = os.path.join(output_dir, f\"{frame_number}.txt\")\n",
        "\n",
        "        # Save the YOLO formatted data to the .txt file\n",
        "        with open(yolo_annotation_path, 'a') as f:\n",
        "            f.write(f\"{class_id} {x_center} {y_center} {w} {h}\\n\")\n"
      ],
      "metadata": {
        "id": "tCX7ZXpBS7ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert CSV Labels to YOLO Format:\n",
        "You need to convert your label files from the CSV format to YOLO format. YOLO requires labels in the following format for each frame:\n",
        "\n",
        "<class_id> <x_center> <y_center> <width> <height>\n",
        "Where:\n",
        "\n",
        "class_id is 0 for \"Moving Non-Human Object\" and 1 for \"Moving In Opposite\".\n",
        "x_center, y_center, width, height are normalized values (relative to the image dimensions).\n",
        "Create the following function to process the video and labels, converting them to YOLO format"
      ],
      "metadata": {
        "id": "d2b6H-nwUAE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "this code is wrong, works only in one video and does not iterate to all vidos."
      ],
      "metadata": {
        "id": "tNSBXPwyhyCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_all_videos(videos_dir, labels_dir, output_dir):\n",
        "    # Loop through all videos in the directory and their corresponding label files\n",
        "    for video_file in os.listdir(videos_dir):\n",
        "        if video_file.endswith('.mp4'):\n",
        "            video_path = os.path.join(videos_dir, video_file)\n",
        "            label_file = video_file.replace('.mp4', '.csv')\n",
        "            label_path = os.path.join(labels_dir, label_file)\n",
        "\n",
        "            # Convert CSV labels to YOLO format\n",
        "            convert_to_yolo_format(video_path, label_path, output_dir)\n",
        "\n",
        "# Process training, validation, and testing datasets\n",
        "process_all_videos('/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Videos/',\n",
        "                   '/content/drive/MyDrive/ProjectDataset/Training/Labels/',\n",
        "                   '/content/drive/MyDrive/ProjectDataset/Train')\n",
        "\n",
        "process_all_videos('/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Validation/Videos/',\n",
        "                   '/content/drive/MyDrive/ProjectDataset/Validation/Labels/',\n",
        "                   '/content/drive/MyDrive/ProjectDataset/Validate')\n",
        "\n",
        "process_all_videos('/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Testing/Videos/',\n",
        "                   '/content/drive/MyDrive/ProjectDataset/Testing/Labels/',\n",
        "                   '/content/drive/MyDrive/ProjectDataset/Test')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "E3UtSHNiT_LE",
        "outputId": "5fe90d4b-ddba-423d-807f-c06d90aac003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/ProjectDataset/Training/Labels/2.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-792c6fd5c04f>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Process training, validation, and testing datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m process_all_videos('/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Videos/',\n\u001b[0m\u001b[1;32m     14\u001b[0m                    \u001b[0;34m'/content/drive/MyDrive/ProjectDataset/Training/Labels/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                    '/content/drive/MyDrive/ProjectDataset/Train')\n",
            "\u001b[0;32m<ipython-input-4-792c6fd5c04f>\u001b[0m in \u001b[0;36mprocess_all_videos\u001b[0;34m(videos_dir, labels_dir, output_dir)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;31m# Convert CSV labels to YOLO format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mconvert_to_yolo_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Process training, validation, and testing datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-6a0d60cc2b6f>\u001b[0m in \u001b[0;36mconvert_to_yolo_format\u001b[0;34m(video_file, csv_file, output_dir)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_yolo_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Read the label CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Open video file to extract frame size (width, height)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ProjectDataset/Training/Labels/2.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "wrong.\n",
        "gonna enhance evverything down."
      ],
      "metadata": {
        "id": "RDaE1Z3eh9GJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating the base_dir i Drive\n",
        "\n",
        "import os\n",
        "\n",
        "# Set the path for base_dir\n",
        "base_dir = '/content/drive/MyDrive/ProjectDataset'\n",
        "# Create the base_dir if it doesn't exist\n",
        "if not os.path.exists(base_dir):\n",
        "    os.makedirs(base_dir)\n",
        "    print(f\"Created directory: {base_dir}\")\n",
        "else:\n",
        "    print(f\"Directory already exists: {base_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13Y8ra5adlxt",
        "outputId": "1e688f7c-32a9-498a-9f09-726afc99f0f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory already exists: /content/drive/MyDrive/ProjectDataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The base_dir is used as the root from which all other relative paths are derived. For example, if your dataset is divided into training, validation, and testing data, each of these would have its own subdirectory within the base_dir.\n",
        "The base_dir in your script represents the base directory path where your dataset is stored. It's a crucial part of the script because it specifies the starting point for all directory path constructions within your functions."
      ],
      "metadata": {
        "id": "M6ttUTVueDtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def process_all_videos_and_labels(base_dir, dataset_type):\n",
        "    video_dir = os.path.join(base_dir, 'HAJJv2.Dataset', dataset_type, 'Videos')\n",
        "    label_dir = os.path.join(base_dir, 'HAJJv2.Dataset', dataset_type, 'Labels')\n",
        "    output_dir = os.path.join(base_dir, 'HAJJv2.Dataset', dataset_type, 'YOLO_Labels')\n",
        "    os.makedirs(output_dir, exist_ok=True)  # Make sure the output directory exists\n",
        "\n",
        "    # Loop through all video files in the video directory\n",
        "    for video_file in os.listdir(video_dir):\n",
        "        video_path = os.path.join(video_dir, video_file)\n",
        "        csv_file = video_file.replace('.mp4', '.csv')  # Assumes label file matches video file name\n",
        "        csv_path = os.path.join(label_dir, csv_file)\n",
        "\n",
        "        if os.path.exists(csv_path):  # Check if the corresponding CSV file exists\n",
        "            convert_to_yolo_format(video_path, csv_path, output_dir)\n",
        "        else:\n",
        "            print(f\"Label file not found for {video_file}\")\n",
        "\n",
        "# Example usage:\n",
        "base_directory = '/content/drive/MyDrive/ProjectDataset'\n",
        "process_all_videos_and_labels(base_directory, 'Training')\n",
        "process_all_videos_and_labels(base_directory, 'Validation')\n",
        "process_all_videos_and_labels(base_directory, 'Testing')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAPNcSZkiD7m",
        "outputId": "88be2ea4-2752-410e-fc8c-7c1bc923c5d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label file not found for 2.mp4\n",
            "Label file not found for 10.mp4\n",
            "Label file not found for 5.mp4\n",
            "Label file not found for 8.mp4\n",
            "Label file not found for 7.mp4\n",
            "Label file not found for 9.mp4\n",
            "Label file not found for 3.mp4\n",
            "Label file not found for 12.mp4\n",
            "Label file not found for 11.mp4\n",
            "Label file not found for 11.mp4\n",
            "Label file not found for 10.mp4\n",
            "Label file not found for 12.mp4\n",
            "Label file not found for 5.mp4\n",
            "Label file not found for 8.mp4\n",
            "Label file not found for 2.mp4\n",
            "Label file not found for 9.mp4\n",
            "Label file not found for 7.mp4\n",
            "Label file not found for 3.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "def process_all_videos_and_labels(base_dir, dataset_type):\n",
        "    video_dir = os.path.join(base_dir, 'HAJJv2.Dataset', dataset_type, 'Videos')\n",
        "    label_dir = os.path.join(base_dir, 'HAJJv2.Dataset', dataset_type, 'Labels')\n",
        "    output_dir = os.path.join(base_dir, 'HAJJv2.Dataset', dataset_type, 'YOLO_Labels')\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Loop through all video files in the video directory\n",
        "    for video_file in os.listdir(video_dir):\n",
        "        video_path = os.path.join(video_dir, video_file)\n",
        "        # Extract the number from the video filename and construct the CSV filename\n",
        "        video_number = re.search(r'\\d+', video_file).group()\n",
        "        csv_file = f\"Dataset_V{video_number}_Train.csv\"\n",
        "        csv_path = os.path.join(label_dir, csv_file)\n",
        "\n",
        "        print(f\"Looking for label file: {csv_path}\")  # Debug: print the path it's checking for CSV\n",
        "\n",
        "        if os.path.exists(csv_path):\n",
        "            convert_to_yolo_format(video_path, csv_path, output_dir)\n",
        "        else:\n",
        "            print(f\"Label file not found for {video_file}\")\n",
        "\n",
        "# Example usage:\n",
        "base_directory = '/content/drive/MyDrive/ProjectDataset'\n",
        "process_all_videos_and_labels(base_directory, 'Training')\n",
        "process_all_videos_and_labels(base_directory, 'Validation')\n",
        "process_all_videos_and_labels(base_directory, 'Testing')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHLeZO0OnIq8",
        "outputId": "38fc5829-16b1-48bf-bcfb-db755640b4c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for label file: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels/Dataset_V2_Train.csv\n",
            "Label file not found for 2.mp4\n",
            "Looking for label file: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels/Dataset_V10_Train.csv\n",
            "Label file not found for 10.mp4\n",
            "Looking for label file: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels/Dataset_V5_Train.csv\n",
            "Label file not found for 5.mp4\n",
            "Looking for label file: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels/Dataset_V8_Train.csv\n",
            "Label file not found for 8.mp4\n",
            "Looking for label file: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels/Dataset_V7_Train.csv\n",
            "Label file not found for 7.mp4\n",
            "Looking for label file: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels/Dataset_V9_Train.csv\n",
            "Label file not found for 9.mp4\n",
            "Looking for label file: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels/Dataset_V3_Train.csv\n",
            "Label file not found for 3.mp4\n",
            "Looking for label file: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Validation/Labels/Dataset_V12_Train.csv\n",
            "Label file not found for 12.mp4\n",
            "Looking for label file: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Validation/Labels/Dataset_V11_Train.csv\n",
            "Label file not found for 11.mp4\n",
            "Looking for label file: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Testing/Labels/Dataset_V11_Train.csv\n",
            "Label file not found for 11.mp4\n",
            "Looking for label file: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Testing/Labels/Dataset_V10_Train.csv\n",
            "Label file not found for 10.mp4\n",
            "Looking for label file: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Testing/Labels/Dataset_V12_Train.csv\n",
            "Label file not found for 12.mp4\n",
            "Looking for label file: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Testing/Labels/Dataset_V5_Train.csv\n",
            "Label file not found for 5.mp4\n",
            "Looking for label file: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Testing/Labels/Dataset_V8_Train.csv\n",
            "Label file not found for 8.mp4\n",
            "Looking for label file: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Testing/Labels/Dataset_V2_Train.csv\n",
            "Label file not found for 2.mp4\n",
            "Looking for label file: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Testing/Labels/Dataset_V9_Train.csv\n",
            "Label file not found for 9.mp4\n",
            "Looking for label file: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Testing/Labels/Dataset_V7_Train.csv\n",
            "Label file not found for 7.mp4\n",
            "Looking for label file: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Testing/Labels/Dataset_V3_Train.csv\n",
            "Label file not found for 3.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def process_videos_and_labels(video_dir, label_dir, output_dir):\n",
        "    # Ensure the output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Loop through all video files in the video directory\n",
        "    for video_file in os.listdir(video_dir):\n",
        "        video_path = os.path.join(video_dir, video_file)\n",
        "        csv_file = video_file.replace('.mp4', '.csv')  # Assumes label file matches video file name\n",
        "        csv_path = os.path.join(label_dir, csv_file)\n",
        "\n",
        "        print(f\"Looking for label file: {csv_path}\")  # Debug: print the path it's checking for CSV\n",
        "\n",
        "        if os.path.exists(csv_path):\n",
        "            convert_to_yolo_format(video_path, csv_path, output_dir)\n",
        "        else:\n",
        "            print(f\"Label file not found for {video_file}\")\n",
        "\n",
        "# Paths for each dataset\n",
        "base_directory = '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset'\n",
        "/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Videos = os.path.join(base_directory, 'Training', 'Videos')\n",
        "/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels = os.path.join(base_directory, 'Training', 'Labels')\n",
        "/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/YOLO_Labels = os.path.join(base_directory, 'Training', 'YOLO_Labels')\n",
        "\n",
        "/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Testing/Videos = os.path.join(base_directory, 'Testing', 'Videos')\n",
        "/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Testing/Labels = os.path.join(base_directory, 'Testing', 'Labels')\n",
        "/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Testing/YOLO_Labels = os.path.join(base_directory, 'Testing', 'YOLO_Labels')\n",
        "\n",
        "/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Validation/Videos = os.path.join(base_directory, 'Validation', 'Videos')\n",
        "/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Validation/Labels = os.path.join(base_directory, 'Validation', 'Labels')\n",
        "/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Validation/YOLO_Labels = os.path.join(base_directory, 'Validation', 'YOLO_Labels')\n",
        "\n",
        "# Process each dataset\n",
        "process_videos_and_labels('/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Videos', '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels', '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/YOLO_Labels')\n",
        "process_videos_and_labels('/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Testing/Videos', '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Testing/Labels', '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Testing/YOLO_Labels')\n",
        "process_videos_and_labels('/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Validation/Videos', '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Validation/Labels', '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Validation/YOLO_Labels')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "oS1HR0wiqQmg",
        "outputId": "23714610-8646-4e7b-fcca-9390ef6fdf07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-9-5c372c69ef07>, line 22)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-5c372c69ef07>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Videos(=, os.path.join(base_directory,, 'Training',, 'Videos'))\u001b[0m\n\u001b[0m                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def convert_to_yolo_format(video_path, csv_path, output_dir):\n",
        "    \"\"\"\n",
        "    Convert labels from CSV format to YOLO format.\n",
        "    Assumes label file contains columns for bounding box coordinates and class names.\n",
        "    \"\"\"\n",
        "    # Placeholder for the conversion process\n",
        "    pass\n",
        "\n",
        "def process_videos_and_labels(video_dir, label_dir, output_dir):\n",
        "    \"\"\"\n",
        "    Process video files and corresponding labels, converting them to YOLO format.\n",
        "\n",
        "    Args:\n",
        "        video_dir (str): Directory containing video files.\n",
        "        label_dir (str): Directory containing corresponding CSV label files.\n",
        "        output_dir (str): Directory where YOLO formatted labels will be saved.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)  # Ensure output directory exists\n",
        "\n",
        "    for video_file in os.listdir(video_dir):\n",
        "        video_path = os.path.join(video_dir, video_file)\n",
        "        csv_file = video_file.replace('.mp4', '.csv')\n",
        "        csv_path = os.path.join(label_dir, csv_file)\n",
        "\n",
        "        if os.path.exists(csv_path):\n",
        "            try:\n",
        "                convert_to_yolo_format(video_path, csv_path, output_dir)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {csv_file}: {e}\")\n",
        "        else:\n",
        "            print(f\"Label file not found for {video_file}\")\n",
        "\n",
        "def setup_dataset_processing(base_directory, dataset_type):\n",
        "    \"\"\"\n",
        "    Setup paths and process a specific dataset type.\n",
        "\n",
        "    Args:\n",
        "        base_directory (str): Base directory where datasets are stored.\n",
        "        dataset_type (str): Type of the dataset ('Training', 'Testing', 'Validation').\n",
        "    \"\"\"\n",
        "    video_dir = os.path.join(base_directory, dataset_type, 'Videos')\n",
        "    label_dir = os.path.join(base_directory, dataset_type, 'Labels')\n",
        "    output_dir = os.path.join(base_directory, dataset_type, 'YOLO_Labels')\n",
        "\n",
        "    process_videos_and_labels(video_dir, label_dir, output_dir)\n",
        "\n",
        "# Base directory where the datasets are located\n",
        "base_directory = '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset'\n",
        "\n",
        "# Setup and process each dataset\n",
        "dataset_types = ['Training', 'Testing', 'Validation']\n",
        "for dataset_type in dataset_types:\n",
        "    setup_dataset_processing(base_directory, dataset_type)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVdEpOd5qcJA",
        "outputId": "ac0a147e-463c-48e2-db14-9ef578e98e87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label file not found for 2.mp4\n",
            "Label file not found for 10.mp4\n",
            "Label file not found for 5.mp4\n",
            "Label file not found for 8.mp4\n",
            "Label file not found for 7.mp4\n",
            "Label file not found for 9.mp4\n",
            "Label file not found for 3.mp4\n",
            "Label file not found for 11.mp4\n",
            "Label file not found for 10.mp4\n",
            "Label file not found for 12.mp4\n",
            "Label file not found for 5.mp4\n",
            "Label file not found for 8.mp4\n",
            "Label file not found for 2.mp4\n",
            "Label file not found for 9.mp4\n",
            "Label file not found for 7.mp4\n",
            "Label file not found for 3.mp4\n",
            "Label file not found for 12.mp4\n",
            "Label file not found for 11.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import cv2\n",
        "\n",
        "def convert_to_yolo_format(csv_path, video_path, output_dir):\n",
        "    \"\"\"\n",
        "    Convert labels from CSV format to YOLO format.\n",
        "\n",
        "    \"\"\"\n",
        "    # Ensure the output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Read the CSV file\n",
        "    labels = pd.read_csv(csv_path)\n",
        "\n",
        "    # Open video to get dimensions\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Could not read video\")\n",
        "        cap.release()\n",
        "        return\n",
        "    height, width, _ = frame.shape\n",
        "    cap.release()\n",
        "\n",
        "    # Filter for specific classes\n",
        "    labels = labels[labels['Classes'].isin(['Moving In Opposite', 'Moving Non-Human Object'])]\n",
        "\n",
        "    # Class mapping to YOLO index\n",
        "    class_mapping = {'Moving In Opposite': 0, 'Moving Non-Human Object': 1}\n",
        "\n",
        "    # Process each label\n",
        "    for index, row in labels.iterrows():\n",
        "        # Calculate YOLO format parameters\n",
        "        x_center = (row['X'] + (row['Width'] / 2)) / width\n",
        "        y_center = (row['Y'] + (row['Height'] / 2)) / height\n",
        "        box_width = row['Width'] / width\n",
        "        box_height = row['Height'] / height\n",
        "        class_id = class_mapping[row['Classes']]\n",
        "\n",
        "        # Write to file\n",
        "        label_filename = f\"{int(row['Frame_No'])}.txt\"\n",
        "        with open(os.path.join(output_dir, label_filename), 'a') as file:\n",
        "            file.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {box_width:.6f} {box_height:.6f}\\n\")\n",
        "\n",
        "def process_dataset(base_dir, dataset_type):\n",
        "    \"\"\"\n",
        "    Process a specific dataset to convert CSV labels to YOLO format.\n",
        "    \"\"\"\n",
        "    video_dir = os.path.join(base_dir, dataset_type, '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Videos')\n",
        "    label_dir = os.path.join(base_dir, dataset_type, '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels')\n",
        "    output_dir = os.path.join(base_dir, dataset_type, '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/YOLO_Labels')\n",
        "\n",
        "    # Process each video\n",
        "    for video_file in os.listdir(video_dir):\n",
        "        video_path = os.path.join(video_dir, video_file)\n",
        "        csv_file = video_file.replace('.mp4', '.csv')\n",
        "        csv_path = os.path.join(label_dir, csv_file)\n",
        "\n",
        "        if os.path.exists(csv_path):\n",
        "            convert_to_yolo_format(csv_path, video_path, output_dir)\n",
        "        else:\n",
        "            print(f\"CSV file not found for video: {video_file}\")\n",
        "\n",
        "# Usage example\n",
        "base_directory = '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset'\n",
        "dataset_type = 'Training'  # Change to 'Validation' or 'Testing' as needed\n",
        "process_dataset(base_directory, dataset_type)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DVYvnTS10PE",
        "outputId": "23870bb4-d6e1-4c7d-84ea-b0d56335ffd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file not found for video: 2.mp4\n",
            "CSV file not found for video: 10.mp4\n",
            "CSV file not found for video: 5.mp4\n",
            "CSV file not found for video: 8.mp4\n",
            "CSV file not found for video: 7.mp4\n",
            "CSV file not found for video: 9.mp4\n",
            "CSV file not found for video: 3.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import cv2\n",
        "\n",
        "def convert_to_yolo_format(csv_path, video_path, output_dir):\n",
        "    # Ensure the output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Try to read the CSV file\n",
        "    try:\n",
        "        labels = pd.read_csv(csv_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not read CSV file at {csv_path}: {e}\")\n",
        "        return\n",
        "\n",
        "    # Try to open the video file to get dimensions\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(f\"Could not read video file at {video_path}\")\n",
        "        cap.release()\n",
        "        return\n",
        "    height, width, _ = frame.shape\n",
        "    cap.release()\n",
        "\n",
        "    # Filter for specific classes and map classes to YOLO indices\n",
        "    labels = labels[labels['Classes'].isin(['Moving In Opposite', 'Moving Non-Human Object'])]\n",
        "    class_mapping = {'Moving In Opposite': 0, 'Moving Non-Human Object': 1}\n",
        "\n",
        "    # Process each label and calculate YOLO format parameters\n",
        "    for index, row in labels.iterrows():\n",
        "        x_center = (row['X'] + row['Width'] / 2) / width\n",
        "        y_center = (row['Y'] + row['Height'] / 2) / height\n",
        "        box_width = row['Width'] / width\n",
        "        box_height = row['Height'] / height\n",
        "        class_id = class_mapping[row['Classes']]\n",
        "\n",
        "        label_filename = f\"{int(row['Frame_No'])}.txt\"\n",
        "        with open(os.path.join(output_dir, label_filename), 'a') as file:\n",
        "            file.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {box_width:.6f} {box_height:.6f}\\n\")\n",
        "\n",
        "def process_dataset(base_dir, dataset_type):\n",
        "    video_dir = os.path.join(base_dir, dataset_type, 'Videos')\n",
        "    label_dir = os.path.join(base_dir, dataset_type, 'Labels')\n",
        "    output_dir = os.path.join(base_dir, dataset_type, 'YOLO_Labels')\n",
        "\n",
        "    # Print paths to check correctness\n",
        "    print(f\"Video Directory: {video_dir}\")\n",
        "    print(f\"Label Directory: {label_dir}\")\n",
        "    print(f\"Output Directory: {output_dir}\")\n",
        "\n",
        "    for video_file in os.listdir(video_dir):\n",
        "        video_path = os.path.join(video_dir, video_file)\n",
        "        csv_file = video_file.replace('.mp4', '.csv')\n",
        "        csv_path = os.path.join(label_dir, csv_file)\n",
        "\n",
        "        # Print expected CSV path for debugging\n",
        "        print(f\"Expected CSV path: {csv_path}\")\n",
        "\n",
        "        if os.path.exists(csv_path):\n",
        "            convert_to_yolo_format(csv_path, video_path, output_dir)\n",
        "        else:\n",
        "            print(f\"CSV file not found for video: {video_file}\")\n",
        "\n",
        "# Usage example\n",
        "base_directory = '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset'\n",
        "dataset_type = 'Training'  # Modify as necessary\n",
        "process_dataset(base_directory, dataset_type)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmfo_fB86Als",
        "outputId": "6a15d9ec-951d-43e9-f4dc-9a41ea07185d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video Directory: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Videos\n",
            "Label Directory: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels\n",
            "Output Directory: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/YOLO_Labels\n",
            "Expected CSV path: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels/2.csv\n",
            "CSV file not found for video: 2.mp4\n",
            "Expected CSV path: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels/10.csv\n",
            "CSV file not found for video: 10.mp4\n",
            "Expected CSV path: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels/5.csv\n",
            "CSV file not found for video: 5.mp4\n",
            "Expected CSV path: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels/8.csv\n",
            "CSV file not found for video: 8.mp4\n",
            "Expected CSV path: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels/7.csv\n",
            "CSV file not found for video: 7.mp4\n",
            "Expected CSV path: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels/9.csv\n",
            "CSV file not found for video: 9.mp4\n",
            "Expected CSV path: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels/3.csv\n",
            "CSV file not found for video: 3.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import cv2\n",
        "\n",
        "def convert_to_yolo_format(csv_path, video_path, output_dir):\n",
        "    \"\"\"\n",
        "    Convert labels from CSV format to YOLO format using video dimensions to normalize bounding box coordinates.\n",
        "    \"\"\"\n",
        "    # Ensure the output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Read the CSV file\n",
        "    labels = pd.read_csv(csv_path)\n",
        "\n",
        "    # Open video to get dimensions\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Could not read video file: \", video_path)\n",
        "        cap.release()\n",
        "        return\n",
        "    height, width, _ = frame.shape\n",
        "    cap.release()\n",
        "\n",
        "    # Filter for specific classes\n",
        "    labels = labels[labels['Classes'].isin(['Moving In Opposite', 'Moving Non-Human Object'])]\n",
        "\n",
        "    # Class mapping to YOLO index\n",
        "    class_mapping = {'Moving In Opposite': 0, 'Moving Non-Human Object': 1}\n",
        "\n",
        "    # Process each label\n",
        "    for index, row in labels.iterrows():\n",
        "        # Calculate YOLO format parameters\n",
        "        x_center = (row['X'] + row['Width'] / 2) / width\n",
        "        y_center = (row['Y'] + row['Height'] / 2) / height\n",
        "        box_width = row['Width'] / width\n",
        "        box_height = row['Height'] / height\n",
        "        class_id = class_mapping[row['Classes']]\n",
        "\n",
        "        # Write to file\n",
        "        label_filename = f\"{int(row['Frame_No'])}.txt\"\n",
        "        with open(os.path.join(output_dir, label_filename), 'a') as file:\n",
        "            file.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {box_width:.6f} {box_height:.6f}\\n\")\n",
        "\n",
        "def process_dataset(base_dir, dataset_type):\n",
        "    \"\"\"\n",
        "    Process a specific dataset to convert CSV labels to YOLO format, matching videos to their labels based on a naming convention.\n",
        "    \"\"\"\n",
        "    video_dir = os.path.join(base_dir, dataset_type, 'Videos')\n",
        "    label_dir = os.path.join(base_dir, dataset_type, 'Labels')\n",
        "    output_dir = os.path.join(base_dir, dataset_type, 'YOLO_Labels')\n",
        "\n",
        "     # Ensure the output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Process each video\n",
        "    for video_file in os.listdir(video_dir):\n",
        "        video_path = os.path.join(video_dir, video_file)\n",
        "        csv_file = f\"HajjDataset_V{video_file.split('.')[0]}_Train.csv\"  # Construct label file name\n",
        "        csv_path = os.path.join(label_dir, csv_file)\n",
        "\n",
        "        if os.path.exists(csv_path):\n",
        "            convert_to_yolo_format(csv_path, video_path, output_dir)\n",
        "        else:\n",
        "            print(f\"CSV file not found for video: {video_file}\")\n",
        "\n",
        "# Usage example\n",
        "base_directory = '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset'\n",
        "process_dataset(base_directory, 'Training')\n"
      ],
      "metadata": {
        "id": "aSeCCKcF-Wkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def check_directories(base_dir, dataset_type):\n",
        "    video_dir = os.path.join(base_dir, dataset_type, 'Videos')\n",
        "    label_dir = os.path.join(base_dir, dataset_type, 'Labels')\n",
        "    output_dir = os.path.join(base_dir, dataset_type, 'YOLO_Labels')\n",
        "\n",
        "    print(f\"Video directory: {video_dir}\")\n",
        "    print(f\"Label directory: {label_dir}\")\n",
        "    print(f\"Output directory: {output_dir}\")\n",
        "\n",
        "    # Check if directories exist\n",
        "    print(\"Checking directories...\")\n",
        "    for path in [video_dir, label_dir, output_dir]:\n",
        "        if os.path.exists(path):\n",
        "            print(f\"Directory exists: {path}\")\n",
        "            print(\"Contents:\", os.listdir(path))\n",
        "        else:\n",
        "            print(f\"Directory does not exist: {path}\")\n",
        "\n",
        "base_directory = '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset'\n",
        "dataset_type = 'Training'\n",
        "check_directories(base_directory, dataset_type)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzsyJHsMBcso",
        "outputId": "fd640cf9-fb14-41bb-a551-13c635e91605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Video directory: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Videos\n",
            "Label directory: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels\n",
            "Output directory: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/YOLO_Labels\n",
            "Checking directories...\n",
            "Directory exists: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Videos\n",
            "Contents: ['2.mp4', '10.mp4', '5.mp4', '8.mp4', '7.mp4', '9.mp4', '3.mp4']\n",
            "Directory exists: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels\n",
            "Contents: ['HajjDataset_V9_Train.csv', 'HajjDataset_V2_Train.csv', 'HajjDataset_V10_Train.csv', 'HajjDataset_V5_Train.csv', 'HajjDataset_V8_Train.csv', 'HajjDataset_V3_Train.csv', 'HajjDataset_V7_Train.csv']\n",
            "Directory exists: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/YOLO_Labels\n",
            "Contents: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def get_video_dimensions(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    cap.release()\n",
        "    return width, height\n",
        "\n",
        "# Example usage\n",
        "video_path = '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Validation/Videos/11.mp4'\n",
        "width, height = get_video_dimensions(video_path)\n",
        "print(f\"Video dimensions: {width}x{height}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSPtXY0gV30r",
        "outputId": "9ae32553-9efc-4168-c76b-99049908ed03"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video dimensions: 1920x1088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, to know the dimintioms of our vidoes, we run this code to be sure to processes our dataset.\n",
        "Before processing your videos, it’s important to know the dimensions (width and height) of the frames. You can find this information using OpenCV:\n",
        "This function opens a video file and retrieves its frame dimensions, which are crucial for accurately normalizing the bounding box coordinates in the YOLO label files."
      ],
      "metadata": {
        "id": "DOQYnIGWWOlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless  # For image processing\n",
        "!pip install pandas  # For handling CSV data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjXcbEbaWN0u",
        "outputId": "fb51c694-e1fd-4165-b920-60b02be62a89"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define the path to the video and the CSV file\n",
        "video_path = '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Validation/Videos/11.mp4'\n",
        "csv_file_path = '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Validation/Labels/HajjDataset_V11_Train.csv'\n",
        "output_frames_path = '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Validation/YOLO_Labels/11'\n",
        "frame_dimensions = (1920, 1088)  # Adjust based on your actual frame size 1920x1088\n",
        "\n",
        "# Create the output directory if it does not exist\n",
        "if not os.path.exists(output_frames_path):\n",
        "    os.makedirs(output_frames_path)\n",
        "\n",
        "# Function to extract frames from a video one frame per second\n",
        "def extract_frames(video_path, out_path, fps=1):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    video_fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    count = 0\n",
        "\n",
        "    while True:\n",
        "        success, image = cap.read()\n",
        "        if not success:\n",
        "            break\n",
        "        if count % (video_fps // fps) == 0:\n",
        "            frame_id = count // (video_fps // fps)\n",
        "            cv2.imwrite(f\"{out_path}/frame_{frame_id:05d}.jpg\", image)\n",
        "        count += 1\n",
        "    cap.release()\n",
        "\n",
        "# Function to convert CSV labels to YOLO format\n",
        "def convert_labels_to_yolo(csv_path, out_path, dimensions):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    interested_classes = {'moving_in_opposite': 0, 'moving_non-human_object': 1}\n",
        "    df = df[df['Classes'].isin(interested_classes.keys())]\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        frame_index = row['Frame_No']\n",
        "        class_id = interested_classes[row['Classes']]\n",
        "        x_center = (row['X'] + row['Width'] / 2) / dimensions[0]\n",
        "        y_center = (row['Y'] + row['Height'] / 2) / dimensions[1]\n",
        "        width = row['Width'] / dimensions[0]\n",
        "        height = row['Height'] / dimensions[1]\n",
        "        label_format = f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
        "\n",
        "        label_path = f\"{out_path}/frame_{frame_index:05d}.txt\"\n",
        "        with open(label_path, 'a') as file:\n",
        "            file.write(label_format + \"\\n\")\n",
        "\n",
        "# Run the functions\n",
        "extract_frames(video_path, output_frames_path)\n",
        "convert_labels_to_yolo(csv_file_path, output_frames_path, frame_dimensions)\n"
      ],
      "metadata": {
        "id": "gjv5fhQfW1ei"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "it makes fram extraction for the specified video.\n",
        "bad"
      ],
      "metadata": {
        "id": "DbwHgqYcx4tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "new start on the structure i got from their website for training"
      ],
      "metadata": {
        "id": "p06obcTDALlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless\n",
        "!pip install pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isq7xLopx-uG",
        "outputId": "d8e14e30-00c1-4151-f1a0-fc5a9ffc9545"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Base directory for dataset\n",
        "base_dir = '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset'\n",
        "\n",
        "# Directory structure\n",
        "dirs = {\n",
        "    'Training': 'train',\n",
        "    'Validation': 'val',\n",
        "    'Testing': 'test'\n",
        "}\n",
        "\n",
        "# Process videos and labels for each dataset part\n",
        "for dataset_part, yolo_part in dirs.items():\n",
        "    video_dir = f'{base_dir}/{dataset_part}/Videos'\n",
        "    label_dir = f'{base_dir}/{dataset_part}/Labels'\n",
        "    output_image_dir = f'{base_dir}/{yolo_part}/images'\n",
        "    output_label_dir = f'{base_dir}/{yolo_part}/labels'\n",
        "\n",
        "    # Create output directories if they don't exist\n",
        "    os.makedirs(output_image_dir, exist_ok=True)\n",
        "    os.makedirs(output_label_dir, exist_ok=True)\n",
        "\n",
        "    # List all videos\n",
        "    for video_file in os.listdir(video_dir):\n",
        "        video_path = os.path.join(video_dir, video_file)\n",
        "        video_base = os.path.splitext(video_file)[0]\n",
        "\n",
        "        # Extract frames\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        video_fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        count = 0\n",
        "\n",
        "        while True:\n",
        "            success, image = cap.read()\n",
        "            if not success:\n",
        "                break\n",
        "            frame_filename = f'{video_base}_frame{count:03d}.jpg'\n",
        "            cv2.imwrite(os.path.join(output_image_dir, frame_filename), image)\n",
        "            count += 1\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        # Convert labels\n",
        "        label_path = os.path.join(label_dir, video_base + '.csv')\n",
        "        df = pd.read_csv(label_path)\n",
        "        interested_classes = {'moving_in_opposite': 0, 'moving_non_human_object': 1}\n",
        "        df = df[df['Classes'].isin(interested_classes.keys())]\n",
        "\n",
        "        frame_dimensions = (1920, 1080)  # Update based on actual frame dimensions\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "            frame_index = row['Frame_No']\n",
        "            class_id = interested_classes[row['Classes']]\n",
        "            x_center = (row['X'] + row['Width'] / 2) / frame_dimensions[0]\n",
        "            y_center = (row['Y'] + row['Height'] / 2) / frame_dimensions[1]\n",
        "            width = row['Width'] / frame_dimensions[0]\n",
        "            height = row['Height'] / frame_dimensions[1]\n",
        "            label_format = f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
        "\n",
        "            label_filename = f'{video_base}_frame{frame_index:03d}.txt'\n",
        "            label_filepath = os.path.join(output_label_dir, label_filename)\n",
        "            with open(label_filepath, 'a') as file:\n",
        "                file.write(label_format + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "wJC5pVxqATOa",
        "outputId": "fa6b0d64-c070-44b7-ce62-af88e0005b3e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels/2.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-ee5cf1d6b7b9>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# Convert labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mlabel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_base\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0minterested_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'moving_in_opposite'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'moving_non_human_object'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Classes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterested_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels/2.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "الكود ممتاز و بسرعه تطلع الفريمات و طلع لي من التدريب 50 فريم لكن الليبل غلط يحتاج بس تعديل لكن بجرب كود ثاني\n"
      ],
      "metadata": {
        "id": "5Z24NciXKt3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Function to retrieve video frame dimensions\n",
        "def get_video_dimensions(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Failed to open video {video_path}\")\n",
        "        return None\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    cap.release()\n",
        "    return width, height\n",
        "\n",
        "# Base directory for dataset\n",
        "base_dir = '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset'\n",
        "\n",
        "# Directory structure mapping from your folder names to YOLO's structure\n",
        "dirs = {\n",
        "    'Training': 'train',\n",
        "    'Validation': 'val',\n",
        "    'Testing': 'test'\n",
        "}\n",
        "\n",
        "# Process videos and labels for each dataset part\n",
        "for dataset_part, yolo_part in dirs.items():\n",
        "    video_dir = f'{base_dir}/{dataset_part}/Videos'\n",
        "    label_dir = f'{base_dir}/{dataset_part}/Labels'\n",
        "    output_image_dir = f'{base_dir}/{yolo_part}/images'\n",
        "    output_label_dir = f'{base_dir}/{yolo_part}/labels'\n",
        "\n",
        "    # Ensure output directories exist\n",
        "    os.makedirs(output_image_dir, exist_ok=True)\n",
        "    os.makedirs(output_label_dir, exist_ok=True)\n",
        "\n",
        "    # List and process all videos\n",
        "    for video_file in os.listdir(video_dir):\n",
        "        video_path = os.path.join(video_dir, video_file)\n",
        "        video_base = os.path.splitext(video_file)[0]\n",
        "\n",
        "        # Extract video frames\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        video_fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        count = 0\n",
        "\n",
        "        while True:\n",
        "            success, image = cap.read()\n",
        "            if not success:\n",
        "                break\n",
        "            frame_filename = f'{video_base}_frame{count:03d}.jpg'\n",
        "            cv2.imwrite(os.path.join(output_image_dir, frame_filename), image)\n",
        "            count += 1\n",
        "        cap.release()\n",
        "\n",
        "        # Convert labels\n",
        "        frame_dimensions = get_video_dimensions(video_path)\n",
        "        if frame_dimensions:\n",
        "            label_file_pattern = video_base.replace('video', 'HajjDataset_V') + '_Train.csv'\n",
        "            label_path = os.path.join(label_dir, label_file_pattern)\n",
        "            if os.path.exists(label_path):\n",
        "                df = pd.read_csv(label_path)\n",
        "                interested_classes = {'moving_in_opposite': 0, 'moving_non_human_object': 1}\n",
        "                df = df[df['Classes'].isin(interested_classes.keys())]\n",
        "\n",
        "                for _, row in df.iterrows():\n",
        "                    frame_index = row['Frame_No']\n",
        "                    class_id = interested_classes[row['Classes']]\n",
        "                    x_center = (row['X'] + row['Width'] / 2) / frame_dimensions[0]\n",
        "                    y_center = (row['Y'] + row['Height'] / 2) / frame_dimensions[1]\n",
        "                    width = row['Width'] / frame_dimensions[0]\n",
        "                    height = row['Height'] / frame_dimensions[1]\n",
        "                    label_format = f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
        "\n",
        "                    label_filename = f'{video_base}_frame{frame_index:03d}.txt'\n",
        "                    label_filepath = os.path.join(output_label_dir, label_filename)\n",
        "                    with open(label_filepath, 'a') as file:\n",
        "                        file.write(label_format + \"\\n\")\n",
        "            else:\n",
        "                print(f\"Label file does not exist: {label_path}\")\n",
        "        else:\n",
        "            print(f\"Failed to retrieve dimensions for video {video_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "j0NzgPHIK9ll",
        "outputId": "e5d76a31-6f98-4f04-eab3-aa76097c4a46"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label file does not exist: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels/2_Train.csv\n",
            "Label file does not exist: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels/10_Train.csv\n",
            "Label file does not exist: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels/5_Train.csv\n",
            "Label file does not exist: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels/8_Train.csv\n",
            "Label file does not exist: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels/7_Train.csv\n",
            "Label file does not exist: /content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset/Training/Labels/9_Train.csv\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c3babb3fa1e8>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mframe_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{video_base}_frame{count:03d}.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_image_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "still theres an issue with the labeling only, great code though. still extracting 50 frames for traning"
      ],
      "metadata": {
        "id": "4BTpVhszRGI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def get_frame_dimensions(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        return None\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    cap.release()\n",
        "    return width, height\n",
        "\n",
        "# Base directory for dataset\n",
        "base_dir = '/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset'  #/content/drive/MyDrive/ProjectDataset/HAJJv2.Dataset\n",
        "\n",
        "# Define suffixes for label files based on dataset parts\n",
        "label_suffix = {\n",
        "    'Training': 'Train',\n",
        "    'Testing': 'Test',\n",
        "    'Validation': 'Validat'\n",
        "}\n",
        "\n",
        "# Process videos and labels for each dataset part\n",
        "for dataset_part, suffix in label_suffix.items():\n",
        "    video_dir = os.path.join(base_dir, dataset_part, 'Videos')\n",
        "    label_dir = os.path.join(base_dir, dataset_part, 'Labels')\n",
        "    output_image_dir = os.path.join(base_dir, dataset_part.lower(), 'images')\n",
        "    output_label_dir = os.path.join(base_dir, dataset_part.lower(), 'labels')\n",
        "\n",
        "    os.makedirs(output_image_dir, exist_ok=True)\n",
        "    os.makedirs(output_label_dir, exist_ok=True)\n",
        "\n",
        "    # List and process all videos\n",
        "    for video_file in os.listdir(video_dir):\n",
        "        video_path = os.path.join(video_dir, video_file)\n",
        "        video_base = os.path.splitext(video_file)[0]\n",
        "        video_number = ''.join(filter(str.isdigit, video_base))  # Extract number from filename\n",
        "\n",
        "        # Extract frames\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        video_fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        count = 0\n",
        "\n",
        "        while True:\n",
        "            success, image = cap.read()\n",
        "            if not success:\n",
        "                break\n",
        "            frame_filename = f'{video_base}_frame{count:03d}.jpg'\n",
        "            cv2.imwrite(os.path.join(output_image_dir, frame_filename), image)\n",
        "            count += 1\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        # Construct the label file name and path\n",
        "        label_file_name = f'HajjDataset_V{video_number}_{suffix}.csv'\n",
        "        label_path = os.path.join(label_dir, label_file_name)\n",
        "\n",
        "        if os.path.exists(label_path):\n",
        "            frame_dimensions = get_frame_dimensions(video_path)\n",
        "            if frame_dimensions:\n",
        "                df = pd.read_csv(label_path)\n",
        "                interested_classes = {'moving_in_opposite': 0, 'moving_non_human_object': 1}\n",
        "                df = df[df['Classes'].isin(interested_classes.keys())]\n",
        "\n",
        "                for _, row in df.iterrows():\n",
        "                    frame_index = row['Frame_No']\n",
        "                    class_id = interested_classes[row['Classes']]\n",
        "                    x_center = (row['X'] + row['Width'] / 2) / frame_dimensions[0]\n",
        "                    y_center = (row['Y'] + row['Height'] / 2) / frame_dimensions[1]\n",
        "                    width = row['Width'] / frame_dimensions[0]\n",
        "                    height = row['Height'] / frame_dimensions[1]\n",
        "                    label_format = f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
        "\n",
        "                    label_filename = f'{video_base}_frame{frame_index:03d}.txt'\n",
        "                    label_filepath = os.path.join(output_label_dir, label_filename)\n",
        "                    with open(label_filepath, 'a') as file:\n",
        "                        file.write(label_format + \"\\n\")\n",
        "            else:\n",
        "                print(f\"Failed to retrieve dimensions for video {video_path}\")\n",
        "        else:\n",
        "            print(f\"Label file does not exist: {label_path}\")\n"
      ],
      "metadata": {
        "id": "auouUY5vRSlk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Rp12gu--W4GE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the PERFECTION speaks\n",
        "\n",
        "done   15m 13s\n",
        "completed at 3:59 AM\n",
        "all frames are extracted, all annotation are made\n",
        "\n",
        "\n",
        "finaliy, do the yalm file:\n",
        "\n",
        "path: ../datasets/HAJJv2  # dataset root dir\n",
        "train: images/train  # train images\n",
        "val: images/val    # val images\n",
        "test: images/test  # test images\n",
        "\n",
        "# Classes\n",
        "names:\n",
        "  0: moving_in_opposite\n",
        "  1: moving_non_human_object\n",
        "  \n"
      ],
      "metadata": {
        "id": "EcxYti0pVWPz"
      }
    }
  ]
}